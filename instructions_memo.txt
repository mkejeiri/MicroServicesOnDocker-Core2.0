https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-docker?view=sql-server-2017&pivots=cs1-bash
docker pull microsoft/mssql-server-linux
docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=!5F&svw1234' -e 'MSSQL_PID=Express' -p 1490:1433 --name=catalogdb microsoft/mssql-server-linux:latest
docker run -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=!5F&svw1234' -e 'MSSQL_PID=Express' -p 1490:1433 --name catalogdb  mcr.microsoft.com/mssql/server:2017-latest
#list active container 
docker ps -a
#remove all images
docker rm $(docker ps -a -f status=exited -f status=created -q)
#connect with sql mgnt at localhost,1490  + credentials above
sqlcmd -S localhost,1490 -U SA -P '!5F&svw1234'
select name from sys.databases
go
#it: interactive command
docker exec -it catalogdb /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P '!5F&svw1234' -Q 'SELECT @@VERSION'
# Microsoft.EntityFrameworkCore.Tools -Version 2.2.4, Enables these commonly used commands:
Add-Migration
Drop-Database
Get-DbContext
Scaffold-DbContext
Script-Migrations
Update-Database

#first migrations 
 dotnet ef migrations add  intialmigrations -o .\Data\Migrations -c ProductCatalogApi.Data.CatalogDbContext
 dotnet ef migrations remove
 #apply migration to the db
 dotnet ef database update intialmigrations  -c ProductCatalogApi.Data.CatalogDbContext

 #Why not putting the seeder inside the configure method in the startup class for dockerized system?
 The configure method in the startup class is devoted to operate in the middleware pipeline! (aka components chain),
 unlike in non dockerized system where we could call the seeder inside configure method, and due the problem encountered by Core,
 the database might not ready in dockerized systems, for that reason Core 2.0 + recommends to inject directly
 the db context for seeding in the program class (main methods).

#configure Swagger : https://github.com/domaindrivendev/Swashbuckle.AspNetCore/blob/master/README-v5.md
#Docker file a recipe for docker image : https://hub.docker.com/r/microsoft/aspnetcore/
docker pull microsoft/aspnetcore:latest
docker pull microsoft/aspnetcore-build:latest
Dockerfile =>
				#build is an alias for the downloaded image
				FROM microsoft/aspnetcore-build:latest as build
				#if code folder doesn't docker will create it
				WORKDIR /code
				#copy project file from my current local p (host) WORKDIR to the current docker container (image)
				COPY . .
				#one all files are copies to the docker container (image), we call restore
				RUN dotnet restore

				#We publish, configuration Release, i.e a release build, this images will have source files + the build
				#it could easily reach 2GB, the best plan is to have runtime+dll's (a smaller runnable image version of our app) (**)
				RUN dotnet publish --output /out/ --configuration Release

				####  to solve the issue (**) we use the docker multistage build
				#use the smaller image (runtime)
				FROM microsoft/aspnetcore:latest
				#copy the only the built artifacts from the previous stages (out folder) to the downloaded runtime container inside folder app
				COPY --from=build /out /app/
				WORKDIR /app
				#this is the entry point for the app to run, dotnet runtime + dll
				ENTRYPOINT ["dotnet", "ProductCatalogApi.dll"]

				##this is an autogen sample
				#FROM microsoft.com/dotnet/core/aspnet:2.2-stretch-slim AS base
				#WORKDIR /code
				#EXPOSE 80
				#EXPOSE 443
				#
				#FROM mcr.microsoft.com/dotnet/core/sdk:2.2-stretch AS build
				#WORKDIR /src
				#COPY ["src/Services/ProductCatalogApi/ProductCatalogApi.csproj", "src/Services/ProductCatalogApi/"]
				#RUN dotnet restore "src/Services/ProductCatalogApi/ProductCatalogApi.csproj"
				#COPY . .
				#WORKDIR "/src/src/Services/ProductCatalogApi"
				#RUN dotnet build "ProductCatalogApi.csproj" -c Release -o /code
				#
				#FROM build AS publish
				#RUN dotnet publish "ProductCatalogApi.csproj" -c Release -o /code
				#
				#FROM base AS final
				#WORKDIR /code
				#COPY --from=publish /code .
				#ENTRYPOINT ["dotnet", "ProductCatalogApi.dll"]

#Run dockerfile 
docker build -t shoes/catalog .

#docker-composer.yml : watch out the indentation, use only space with (same 3 spaces at each level), also since a linux image is case sensitive (we have a Dockerfile and not a dockerfile)

version: "3.2"

networks:
   frontend:
   backend:

services:
   catalog:
      build:
         context: .\src\Services\productCatalogApi
         dockerfile: Dockerfile
      environment:
         - DatabaseServer=mssqlserver
         - DatabaseName=CatalogDb
         - DatabaseUser=sa
         - DatabaseUserPassword=!5F&svw1234
      container_name: catalogapi
      ports:
         - "5004:80"
      networks:
         - backend
         - frontend
      depends_on:
         - mssqlserver

   mssqlserver:
      image: microsoft/mssql-server-linux:latest
      ports:
         - "1490:1433"
      container_name: mssqlcontainer
      environment:
         - ACCEPT_EULA=Y
         - 'SA_PASSWORD=!5F&svw1234'
      networks:
         - backend


add <PublishWithAspNetCoreTargetManifest>false</PublishWithAspNetCoreTargetManifest> to the ProductCatalogApi.csproj file to avoid conflict with the downgraded version .netcore  docker image and our solution
or downgrade to 2.0.0 (which I did here)

#remove all orphan images from docker 
docker system prune
# check passive container
docker ps -a

#run the docker-composer
docker-compose build

#start our mssqlserver service
docker-compose up mssqlserver

#start our mssqlserver service in the background
docker-compose up -d mssqlserver

#start our catalog service and go to http://localhost:5004/swagger/index.html , we use port 5004 because it's free
docker-compose up catalog

#remove all containers
docker-compose down
docker-compose build
docker-compose up mssqlserver
docker-compose up catalog



#docker-composer.yml (updated): watch out the dependencies order and ENV var
			version: "3.2"

			networks:
			   frontend:
			   backend:

			services:
			   webmvc:
				  build:
					 context: .\src\Web\WebMvc
					 dockerfile: Dockerfile
				  environment:
					 - ASPNETCORE_ENVIRONMENT=Development
					 - CatalogUrl=http://catalog
				  container_name: webfront
				  ports:
					 - "5500:80"
				  networks:
					 - frontend
				  depends_on:
					 - catalog
			   catalog:
				  build:
					 context: .\src\Services\productCatalogApi
					 dockerfile: Dockerfile
				  environment:
					 - DatabaseServer=mssqlserver
					 - DatabaseName=CatalogDb
					 - DatabaseUser=sa
					 - DatabaseUserPassword=!5F&svw1234
				  container_name: catalogapi
				  ports:
					 - "5004:80"
				  networks:
					 - backend
					 - frontend
				  depends_on:
					 - mssqlserver

			   mssqlserver:
				  image: microsoft/mssql-server-linux:latest
				  ports:
					 - "1490:1433"
				  container_name: mssqlcontainer
				  environment:
					 - ACCEPT_EULA=Y
					 - 'SA_PASSWORD=!5F&svw1234'
				  networks:
					 - backend

#Athentication and authorization
see https://github.com/IdentityServer/IdentityServer4.Samples/tree/master/Quickstarts
see https://identityserver4.readthedocs.io/en/latest/intro/big_picture.html
1- create TokenServiceApi with view-model
2- add IdentityServer4 from nuget pack
3- add IdentityServer4.Asp  from nuget pack :this will be used as a bridge between IdentityServer4 and asp core identity

ipconfig gives:
Ethernet adapter vEthernet (DockerNAT):  10.0.75.1
IdentityUrl=http://10.0.75.1:5300 since it's an external component running on port 5300


#create a CartApi
- it's a redis db for storing and retrieving the shopping cart for a customer
- key, value pair db (cartId, Json representation of a cart)
- customerId=buyerId=cartId
- Exceptions are handled globally by HttpGlobalExceptionFilter class and register in the pipeline in the startup class
- two kind of exceptions: CartDomainException (sent as a BadRequest) and system exception (sent as 500 Internal Server Error)
- Swagger also added and authentication is skipped for Swagger now

#Implementation
added docker-compose.CartApi.redis
version: "3.2"
networks:
  backend:
services:
  basket.data:
    image: redis
    ports:
      - "6377:6379"
    networks:
      - backend

contains a single docker container service named basket.data and built from image:redis downloaded from docker hub
port is remapped from 6379 (redis default) to 6377 and placed in software defined backend network.

run =>
docker pull redis:latest
docker-compose -f docker-compose.CartApi.redis.yml build
docker-compose -f docker-compose.CartApi.redis.yml up basket.data


#Adding all docker-compose for shopping cart Api
services:
  cart:
    image: cartimage
    build: 
      context: .\src\Services\CartApi
      dockerfile: Dockerfile
    environment: 
      - ASPNETCORE_ENVIRONMENT=Development
    container_name: cartapi
    ports:
      - "5500:80"
    networks:
      - backend
      - frontend
    depends_on:
      - basket.data
  
  basket.data:
    image: redis
    ports:
      - "6377:6379"
    networks:
      - backend

#Connection string need also to be changed from ConnectionString": "127.0.0.1:6377" to  "ConnectionString": "basket.data"

#CartApi protection
need to allow only swagger and webmvc client.
	a- Added ConfigureAuthServices config in CartApi startup class
	b- we should also add swagger UI in the list of client in the tokenServiceApi config.cs


This an example of docker yml file where we keep a data in separate volume :  odata:/var/lib/mysql and also using 
order.server:
    container_name: ${MYSQL_SERVER_NAME} <-Env variable from .env file
    image: mysql/mysql-server:5.7 <- this will be pulled down from docker hub if not locally available.
    restart: always
    volumes:
      - odata:/var/lib/mysql <-- this volume will keep the data even if the container is destroyed.
    ports:
      - "3406:3306" 
	environment:
      MYSQL_RANDOM_ROOT_PASSWORD: !!str yes <-- Mysql admin tool pass
         
    env_file:
      - secrets.env   <-- reading from secrets.env all credentials and not to push to source control
    networks:
      - backend

The ENV variables and files allow us to changes settings without recompiling the docker images. 
The ENV's are recongnized automatically by docker compose file

f switch to select a specific yml file and buid the required containers
docker-compose -f .\docker-compose.OrderApi.yml build
docker-compose -f .\docker-compose.OrderApi.yml up order.server

docker exec -it mysqldb mysql -u root -p and then you're prompted for a [password] <-- [password]  is received after starting up the container
show databases

we have to make sure that mysql table are created via migration before we reach the end of the pipeline, WaitForDBInit method in the startup class 
is there to make sure that we get a connection before the migration are executed.

after migrations:
use  OrdersDb; <-- is case sensitive

docker rmi --force shoes/cart cartimage microservicesondocker_webmvc microservicesondocker_catalog

#Add migration from nuget console, make sure you are in correct project
add-migration Initial -output Data/Migrations


#Service bus rabbitmq
for IOC autofac see startup.cs in the OrderApi
Create an event sourcing in Messaging/OrderCompletedEvent to allow orderApi to publish an event when an order is made
in docker-compose file we need to specify the network as the same as the pulisher and consummers network 
otherwise it wouldn't work. here both publisher and consumer microservices have the front and backend network!!!
also the volumes should specified as ~/rabbitmq:/var/lib/rabbitmq/mnesia   with mnesia something has to do with erlang!!!
we should also add the rabbitmq service in the dependencies in orderApi section

rabbitmq:
     image: rabbitmq:3-management
     container_name: rabbitmq
     hostname: myrabbitmq
     ports:
        - "15672:15672"
        - "5672:5672"
        - "5671:5671"
     volumes:
        - ~/rabbitmq:/var/lib/rabbitmq/mnesia   
     networks:
       - backend 


#rebuid all image
docker-compose build
docker-compose up cart rabbitmq mssqlserver
and go to localhost:15672

#start also other services 
docker-compose up order tokenserver cart catalog webmvc
